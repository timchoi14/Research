{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.filters import sobel\n",
    "from skimage.measure import shannon_entropy\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "from scipy.ndimage import sobel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_color_variance(image):\n",
    "    \"\"\"\n",
    "    Compute color variance for an image.\n",
    "    Args:\n",
    "        image (Tensor): Input image of shape (3, H, W).\n",
    "    Returns:\n",
    "        float: Color variance.\n",
    "    \"\"\"\n",
    "    image = image.cpu().numpy()  # Convert to NumPy array\n",
    "    variance = np.var(image, axis=(1, 2))  # Variance across H, W for each channel\n",
    "    return variance.mean()  # Average variance across RGB channels\n",
    "\n",
    "def compute_edge_density(image):\n",
    "    \"\"\"\n",
    "    Compute edge density for an image using Sobel filter.\n",
    "    Args:\n",
    "        image (Tensor): Input image of shape (3, H, W).\n",
    "    Returns:\n",
    "        float: Edge density.\n",
    "    \"\"\"\n",
    "    image_gray = image.mean(dim=0).cpu().numpy()  # Convert to grayscale\n",
    "    edges = sobel(image_gray)  # Sobel filter for edge detection\n",
    "    edge_density = np.sum(edges > 0) / edges.size  # Proportion of edge pixels\n",
    "    return edge_density\n",
    "\n",
    "def compute_entropy(image):\n",
    "    \"\"\"\n",
    "    Compute entropy for an image.\n",
    "    Args:\n",
    "        image (Tensor): Input image of shape (3, H, W).\n",
    "    Returns:\n",
    "        float: Entropy value.\n",
    "    \"\"\"\n",
    "    image_gray = image.mean(dim=0).cpu().numpy()  # Convert to grayscale\n",
    "    hist, _ = np.histogram(image_gray, bins=256, range=(0, 1), density=True)  # Normalized histogram\n",
    "    return entropy(hist + 1e-6)  # Avoid log(0) with small offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyExitResNet34(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape=(3, 224, 224), initial_threshold=0.8, decay_rate=0.1):\n",
    "        super(EarlyExitResNet34, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet34\n",
    "        self.resnet34 = models.resnet34(pretrained=True)\n",
    "        \n",
    "        # Replace the final classifier to match the target classes\n",
    "        self.resnet34.fc = nn.Linear(self.resnet34.fc.in_features, num_classes)\n",
    "        \n",
    "        # Compute feature map sizes for early exits dynamically\n",
    "        self.exit1_size = self._compute_flattened_size(\n",
    "            nn.Sequential(\n",
    "                self.resnet34.conv1,\n",
    "                self.resnet34.bn1,\n",
    "                self.resnet34.relu,\n",
    "                self.resnet34.maxpool\n",
    "            ),\n",
    "            input_shape\n",
    "        )\n",
    "        self.exit2_size = self._compute_flattened_size(\n",
    "            nn.Sequential(\n",
    "                self.resnet34.conv1,\n",
    "                self.resnet34.bn1,\n",
    "                self.resnet34.relu,\n",
    "                self.resnet34.maxpool,\n",
    "                self.resnet34.layer1\n",
    "            ),\n",
    "            input_shape\n",
    "        )\n",
    "        \n",
    "        # Early exit fully connected layers\n",
    "        self.exit1_fc = nn.Linear(self.exit1_size, num_classes)\n",
    "        self.exit2_fc = nn.Linear(self.exit2_size, num_classes)\n",
    "        \n",
    "        # Early exit thresholds\n",
    "        self.initial_threshold = initial_threshold\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def _compute_flattened_size(self, layers, input_shape):\n",
    "        \"\"\"\n",
    "        Helper function to compute the flattened size of feature maps after a sequence of layers.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_shape)  # Batch size of 1\n",
    "            output = layers(dummy_input)\n",
    "        return output.view(1, -1).size(1)\n",
    "\n",
    "    def _should_exit(self, x, fc, threshold):\n",
    "        \"\"\"\n",
    "        Helper function to determine if the model should exit early based on confidence.\n",
    "        \"\"\"\n",
    "        x_exit = torch.flatten(x, start_dim=1)  # Flatten the feature map\n",
    "        logits = fc(x_exit)  # Pass through the exit classifier\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        confidence, _ = torch.max(probs, dim=1)\n",
    "        return confidence.item() > threshold, logits\n",
    "    \n",
    "    def _compute_dynamic_threshold(self, image):\n",
    "        \"\"\"\n",
    "        Compute dynamic thresholds based on image metrics.\n",
    "        Args:\n",
    "            image (Tensor): Input image of shape (B, 3, H, W).\n",
    "        Returns:\n",
    "            float: Adjusted threshold for early exits.\n",
    "        \"\"\"\n",
    "        batch_size = image.size(0)\n",
    "        thresholds = []\n",
    "        for i in range(batch_size):\n",
    "            color_var = compute_color_variance(image[i])\n",
    "            edge_density = compute_edge_density(image[i])\n",
    "            entropy_value = compute_entropy(image[i])\n",
    "\n",
    "            # Example formula for dynamic threshold\n",
    "            dynamic_threshold = (\n",
    "                0.5 * (color_var / 255) +  # Normalize variance\n",
    "                0.3 * edge_density +\n",
    "                0.2 * (entropy_value / np.log(256))  # Normalize entropy\n",
    "            )\n",
    "            thresholds.append(dynamic_threshold)\n",
    "\n",
    "        return thresholds\n",
    "\n",
    "    def forward(self, x, thresholds=None):\n",
    "        if thresholds is None:\n",
    "            thresholds = self._compute_dynamic_threshold(x)  # Dynamically compute thresholds\n",
    "\n",
    "        # Initial layers\n",
    "        x = self.resnet34.conv1(x)\n",
    "        x = self.resnet34.bn1(x)\n",
    "        x = self.resnet34.relu(x)\n",
    "        x = self.resnet34.maxpool(x)\n",
    "\n",
    "        # Early exit 1\n",
    "        if thresholds[0] is not None:\n",
    "            should_exit, logits = self._should_exit(x, self.exit1_fc, thresholds[0])\n",
    "            if should_exit:\n",
    "                return logits\n",
    "\n",
    "        # ResNet block 1\n",
    "        x = self.resnet34.layer1(x)\n",
    "\n",
    "        # Early exit 2\n",
    "        if thresholds[1] is not None:\n",
    "            should_exit, logits = self._should_exit(x, self.exit2_fc, thresholds[1])\n",
    "            if should_exit:\n",
    "                return logits\n",
    "\n",
    "        # Remaining ResNet layers\n",
    "        x = self.resnet34.layer2(x)\n",
    "        x = self.resnet34.layer3(x)\n",
    "        x = self.resnet34.layer4(x)\n",
    "\n",
    "        # Final classifier\n",
    "        x = self.resnet34.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.resnet34.fc(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preparation ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 as an example dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "val_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model, Loss, and Optimizer ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EarlyExitResNet34(num_classes=10, input_shape=(3, 224, 224)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # Dynamic thresholds applied here\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total * 100\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_accuracy:.2f}%\")\n",
    "    torch.save(model.state_dict(), \"resnet34_early_exit_cifar10_adaptive.pth\")\n",
    "    print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation Function ---\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images, thresholds=None)  # No early exit during validation\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update metrics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct / total * 100\n",
    "    print(f\"Validation: Loss = {val_loss:.4f}, Accuracy = {val_accuracy:.2f}%\")\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:11:02<00:00, 10.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1658, Accuracy = 94.25%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.3554, Accuracy = 89.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:10:25<00:00, 10.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1243, Accuracy = 95.68%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.2959, Accuracy = 91.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:10:07<00:00, 10.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1024, Accuracy = 96.40%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.3274, Accuracy = 90.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:10:09<00:00, 10.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0758, Accuracy = 97.41%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.3435, Accuracy = 90.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:10:17<00:00, 10.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0634, Accuracy = 97.79%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.3071, Accuracy = 91.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:10:02<00:00, 10.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0601, Accuracy = 97.94%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.3794, Accuracy = 90.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:10:12<00:00, 10.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0554, Accuracy = 98.07%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.2808, Accuracy = 91.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:11:35<00:00, 10.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0390, Accuracy = 98.68%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.3540, Accuracy = 91.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:08:53<00:00, 10.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0442, Accuracy = 98.49%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.4110, Accuracy = 90.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [1:07:59<00:00, 10.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0430, Accuracy = 98.50%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 0.3273, Accuracy = 91.83%\n"
     ]
    }
   ],
   "source": [
    "# --- Training and Validation Loop ---\n",
    "for epoch in range(10):\n",
    "    train(model, train_loader, optimizer, criterion, device, num_epochs=1)\n",
    "    validate(model, val_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Test the model on a given test dataset.\n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        device (torch.device): Device for computation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    early_exit_counts = [0] * (model.num_exits + 1)  # Count per exit point\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass with dynamic thresholds\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Determine the exit point\n",
    "            if isinstance(outputs, tuple):  # Outputs can be (logits, exit_point)\n",
    "                logits, exit_point = outputs\n",
    "                early_exit_counts[exit_point] += 1\n",
    "            else:\n",
    "                logits = outputs\n",
    "                early_exit_counts[-1] += 1  # Count for the final exit\n",
    "\n",
    "            # Compute predictions\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Overall accuracy\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Exit point statistics\n",
    "    for i, count in enumerate(early_exit_counts):\n",
    "        if i < model.num_exits:\n",
    "            print(f\"Exit {i + 1}: {count} samples exited\")\n",
    "        else:\n",
    "            print(f\"Final Exit: {count} samples exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timot\\AppData\\Local\\Temp\\ipykernel_16228\\3599189430.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"resnet34_early_exit_cifar10_adaptive.pth\"))  # Replace with the correct path\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EarlyExitResNet34' object has no attribute 'num_exits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# --- Test the Model ---\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[95], line 12\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model, test_loader, device)\u001b[0m\n\u001b[0;32m     10\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 12\u001b[0m early_exit_counts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_exits\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Count per exit point\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EarlyExitResNet34' object has no attribute 'num_exits'"
     ]
    }
   ],
   "source": [
    "# --- Load Trained Model ---\n",
    "model = EarlyExitResNet34(num_classes=10, input_shape=(3, 224, 224))\n",
    "model.load_state_dict(torch.load(\"resnet34_early_exit_cifar10_adaptive.pth\"))  # Replace with the correct path\n",
    "model.to(device)\n",
    "\n",
    "# --- Test the Model ---\n",
    "test_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
