{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.filters import sobel\n",
    "from skimage.measure import shannon_entropy\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "from scipy.ndimage import sobel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_color_variance(image):\n",
    "    \"\"\"\n",
    "    Compute color variance for an image.\n",
    "    Args:\n",
    "        image (Tensor): Input image of shape (3, H, W).\n",
    "    Returns:\n",
    "        float: Color variance.\n",
    "    \"\"\"\n",
    "    image = image.cpu().numpy()  # Convert to NumPy array\n",
    "    variance = np.var(image, axis=(1, 2))  # Variance across H, W for each channel\n",
    "    return variance.mean()  # Average variance across RGB channels\n",
    "\n",
    "def compute_edge_density(image):\n",
    "    \"\"\"\n",
    "    Compute edge density for an image using Sobel filter.\n",
    "    Args:\n",
    "        image (Tensor): Input image of shape (3, H, W).\n",
    "    Returns:\n",
    "        float: Edge density.\n",
    "    \"\"\"\n",
    "    image_gray = image.mean(dim=0).cpu().numpy()  # Convert to grayscale\n",
    "    edges = sobel(image_gray)  # Sobel filter for edge detection\n",
    "    edge_density = np.sum(edges > 0) / edges.size  # Proportion of edge pixels\n",
    "    return edge_density\n",
    "\n",
    "def compute_entropy(image):\n",
    "    \"\"\"\n",
    "    Compute entropy for an image.\n",
    "    Args:\n",
    "        image (Tensor): Input image of shape (3, H, W).\n",
    "    Returns:\n",
    "        float: Entropy value.\n",
    "    \"\"\"\n",
    "    image_gray = image.mean(dim=0).cpu().numpy()  # Convert to grayscale\n",
    "    hist, _ = np.histogram(image_gray, bins=256, range=(0, 1), density=True)  # Normalized histogram\n",
    "    return entropy(hist + 1e-6)  # Avoid log(0) with small offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyExitResNet34(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape=(3, 224, 224), initial_threshold=0.8, decay_rate=0.1):\n",
    "        super(EarlyExitResNet34, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet34\n",
    "        #self.resnet34 = models.resnet34(pretrained=True)\n",
    "        self.resnet34 = models.resnet34(weights=None)\n",
    "        # Replace the final classifier to match the target classes\n",
    "        self.resnet34.fc = nn.Linear(self.resnet34.fc.in_features, num_classes)\n",
    "        \n",
    "        # Compute feature map sizes for early exits dynamically\n",
    "        self.exit1_size = self._compute_flattened_size(\n",
    "            nn.Sequential(\n",
    "                self.resnet34.conv1,\n",
    "                self.resnet34.bn1,\n",
    "                self.resnet34.relu,\n",
    "                self.resnet34.maxpool\n",
    "            ),\n",
    "            input_shape\n",
    "        )\n",
    "        self.exit2_size = self._compute_flattened_size(\n",
    "            nn.Sequential(\n",
    "                self.resnet34.conv1,\n",
    "                self.resnet34.bn1,\n",
    "                self.resnet34.relu,\n",
    "                self.resnet34.maxpool,\n",
    "                self.resnet34.layer1\n",
    "            ),\n",
    "            input_shape\n",
    "        )\n",
    "        \n",
    "        # Early exit fully connected layers\n",
    "        self.exit1_fc = nn.Linear(self.exit1_size, num_classes)\n",
    "        self.exit2_fc = nn.Linear(self.exit2_size, num_classes)\n",
    "        \n",
    "        # Early exit thresholds\n",
    "        self.initial_threshold = initial_threshold\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def _compute_flattened_size(self, layers, input_shape):\n",
    "        \"\"\"\n",
    "        Helper function to compute the flattened size of feature maps after a sequence of layers.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_shape)  # Batch size of 1\n",
    "            output = layers(dummy_input)\n",
    "        return output.view(1, -1).size(1)\n",
    "\n",
    "    def _should_exit(self, x, fc, threshold):\n",
    "        \"\"\"\n",
    "        Helper function to determine if the model should exit early based on confidence.\n",
    "        \"\"\"\n",
    "        if isinstance(threshold, list) or isinstance(threshold, torch.Tensor):\n",
    "            raise ValueError(\"Threshold should be a scalar, not a list or tensor.\")\n",
    "\n",
    "        x_exit = torch.flatten(x, start_dim=1)  # Flatten the feature map\n",
    "        logits = fc(x_exit)  # Pass through the exit classifier\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        confidence, _ = torch.max(probs, dim=1)\n",
    "        # Ensure comparison is element-wise\n",
    "        return confidence > threshold, logits\n",
    "    \n",
    "    def _compute_dynamic_threshold(self, image):\n",
    "        \"\"\"\n",
    "        Compute dynamic thresholds based on image metrics.\n",
    "        Args:\n",
    "            image (Tensor): Input image of shape (B, 3, H, W).\n",
    "        Returns:\n",
    "            float: Adjusted threshold for early exits.\n",
    "        \"\"\"\n",
    "        batch_size = image.size(0)\n",
    "        thresholds = []\n",
    "        for i in range(batch_size):\n",
    "            color_var = compute_color_variance(image[i])\n",
    "            edge_density = compute_edge_density(image[i])\n",
    "            entropy_value = compute_entropy(image[i])\n",
    "\n",
    "            # Example formula for dynamic threshold\n",
    "            dynamic_threshold = (\n",
    "                0.5 * (color_var / 255) +  # Normalize variance\n",
    "                0.4 * edge_density +\n",
    "                0.3 * (entropy_value / np.log(256))  # Normalize entropy\n",
    "            )\n",
    "            thresholds.append(dynamic_threshold)\n",
    "\n",
    "        return thresholds\n",
    "\n",
    "    def forward(self, x, thresholds=None):\n",
    "        #print(f\"Input shape: {x.shape}\")\n",
    "        \n",
    "        # Ensure thresholds are set\n",
    "        if thresholds is None:\n",
    "            thresholds = self._compute_dynamic_threshold(x)\n",
    "            #print(f\"Computed dynamic thresholds: {thresholds}\")\n",
    "        elif isinstance(thresholds, (float, int)):\n",
    "            thresholds = [thresholds] * x.size(0)\n",
    "        \n",
    "        # Convert thresholds to scalars\n",
    "        thresholds = [t.item() if isinstance(t, torch.Tensor) else t for t in thresholds]\n",
    "        #print(f\"Final thresholds for batch: {thresholds}\")\n",
    "\n",
    "        # Initial layers\n",
    "        x = self.resnet34.conv1(x)\n",
    "        x = self.resnet34.bn1(x)\n",
    "        x = self.resnet34.relu(x)\n",
    "        x = self.resnet34.maxpool(x)\n",
    "\n",
    "        # Early exit 1\n",
    "        if thresholds[0] is not None:\n",
    "            should_exit, logits = self._should_exit(x, self.exit1_fc, thresholds[0])\n",
    "            #print(f\"Exit 1 decision: {should_exit}\")\n",
    "            if should_exit.any():  # Exit if any image in the batch should exit\n",
    "                return logits\n",
    "\n",
    "        # ResNet block 1\n",
    "        x = self.resnet34.layer1(x)\n",
    "        # Early exit 2\n",
    "        if thresholds[0] is not None:\n",
    "            should_exit, logits = self._should_exit(x, self.exit2_fc, thresholds[0])\n",
    "            #print(f\"Exit 2 decision: {should_exit}\")\n",
    "            if should_exit.any():  # Exit if any image in the batch should exit\n",
    "                return logits\n",
    "        \n",
    "\n",
    "        # Remaining ResNet layers\n",
    "        x = self.resnet34.layer2(x)\n",
    "        \n",
    "        x = self.resnet34.layer3(x)\n",
    "        x = self.resnet34.layer4(x)\n",
    "\n",
    "        x = self.resnet34.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.resnet34.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preparation ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 as an example dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "val_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model, Loss, and Optimizer ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EarlyExitResNet34(num_classes=10, input_shape=(3, 224, 224)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Compute dynamic thresholds for the batch\n",
    "            thresholds = model._compute_dynamic_threshold(images)  # A list of thresholds for each sample in the batch\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with thresholds\n",
    "            outputs = model(images, thresholds=thresholds)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total * 100\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_accuracy:.2f}%\")\n",
    "    torch.save(model.state_dict(), \"resnet34_early_exit_cifar10_adaptive_plsv3.pth\")\n",
    "    print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation Function ---\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images, thresholds=None)  # No early exit during validation\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update metrics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct / total * 100\n",
    "    print(f\"Validation: Loss = {val_loss:.4f}, Accuracy = {val_accuracy:.2f}%\")\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   3%|▎         | 10/391 [00:37<23:44,  3.74s/it]c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_histograms_impl.py:902: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n",
      "Epoch 1/1: 100%|██████████| 391/391 [11:24<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 22.8180, Accuracy = 27.56%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 9.3171, Accuracy = 31.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [08:36<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 6.4269, Accuracy = 34.20%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 4.7840, Accuracy = 39.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [08:43<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 3.5384, Accuracy = 42.21%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 2.8325, Accuracy = 40.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [08:41<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 2.1503, Accuracy = 49.06%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 2.1258, Accuracy = 48.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [08:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.6608, Accuracy = 52.90%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 1.8034, Accuracy = 48.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [08:43<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.3842, Accuracy = 56.48%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 1.6645, Accuracy = 49.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [08:59<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.2576, Accuracy = 58.62%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 1.4751, Accuracy = 53.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [08:51<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.1945, Accuracy = 60.09%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 1.5035, Accuracy = 52.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [08:55<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.1554, Accuracy = 61.07%\n",
      "Model saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Loss = 1.4115, Accuracy = 54.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 391/391 [09:14<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.1157, Accuracy = 62.34%\n",
      "Model saved successfully!\n",
      "Validation: Loss = 1.4583, Accuracy = 53.20%\n"
     ]
    }
   ],
   "source": [
    "# --- Training and Validation Loop ---\n",
    "for epoch in range(10):\n",
    "    train(model, train_loader, optimizer, criterion, device, num_epochs=1)\n",
    "    validate(model, val_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    #early_exit_counts = [0] * (model.num_exits + 1)  # Count per exit point\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass with dynamic thresholds\n",
    "            logits = model(images)\n",
    "\n",
    "            # Count exits\n",
    "            #early_exit_counts[exit_point] += logits.size(0)\n",
    "\n",
    "            # Compute predictions\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Overall accuracy\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timot\\AppData\\Local\\Temp\\ipykernel_21644\\3599189430.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"resnet34_early_exit_cifar10_adaptive.pth\"))  # Replace with the correct path\n",
      "Testing: 100%|██████████| 313/313 [04:39<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Load Trained Model ---\n",
    "model = EarlyExitResNet34(num_classes=10, input_shape=(3, 224, 224))\n",
    "model.load_state_dict(torch.load(\"resnet34_early_exit_cifar10_adaptive.pth\"))  # Replace with the correct path\n",
    "model.to(device)\n",
    "\n",
    "# --- Test the Model ---\n",
    "test_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
